<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>NAACL 24 Tutorial: Explanations in the Era of Large Language Models</title>
    <meta name="viewport" content="width=device-width">
    <meta name="description" content="">
    <!--link rel="canonical" href="xai-hcee.github.io/"-->

    <!-- Custom CSS -->
    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">
</head>


    <body>

    <header class="site-header">

  <div class="wrap">
    <a class="site-title" href="https://underline.io/events/458/sessions?eventSessionId=17411&searchGroup=lecture"><font color='#205caa'> NAACL 24 Tutorial: Explanations in the Era of Large Language Models</font> </a> 

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">
	  
      <a class="page-link" href="#overview">Overview</a>
        
      <a class="page-link" href="#speakers">Speakers</a>
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">
  <!-- header class="post-header">
    <h1>NAACL 24 Tutorial: Explanations in the Era of Large Language Models</h1>
  </header-->
  <article class="post-content">
  <h2 id="overview">Overview</h2>

<ul>
  <li><strong>Date</strong>: June 16, 2024</li>
  <li><strong>Location</strong>: Don Alberto 3</li>
  <li><strong>Schedule</strong>
    <ul>
      <li>9:00 - 9:40 Introduction, desiderata</li>
      <li>9:40 - 10:30 Prompt-based explanations</li>
      <li>10:30 - 11:00 Coffee break</li>
      <li>11:00 - 11:45 Data attribution</li>
      <li>11:45 - 12:30 Transformer Understanding</li>
      <li>12:30 - 12:45 Conclusion and Q&amp;A</li>
    </ul>
  </li>
  <!--li><strong>Ask your question</strong>: <a href="https://app.sli.do/event/awQq8cDeXyxQYFP1WnfGqB">sli.do</a>.</li-->
  <li><strong>Underline page</strong>: <a href="https://2024.naacl.org/program/tutorials/">Explanations in the Era of Large Language Models</a></li>
</ul>

<p>Explanation has long been a part of communications, where humans use language to elucidate each other and transmit information about the mechanisms of events. There have been numerous works that study the structures of the explanations and their utility to humans.</p>

<p>At the same time, explanation relates to a collection of research directions in natural language processing (and more broadly, computer vision and machine learning) where researchers develop computational approaches to explain the (usually deep neural network) models. Explanation has received rising attention. </p>
    
<p>In recent months, the advance of large language models (LLMs) provides unprecedented opportunities to leverage their reasoning abilities, both as tools to produce explanations and as the subjects of explanation analysis. On the other hand, the sheer sizes and the opaque nature of LLMs introduce challenges to the explanation methods. In this tutorial, we intend to review these opportunities and challenges of explanations in the era of LLMs, connect some researches that were previously studied by different research groups, and hopefully sparkle the thoughts of new research directions.</p>

<!--p>Click on each chapter to view the video recording and the slides:</p>
<ul>
  <li><a href="https://xai-hcee.github.io/chapter_0.html">Chapter 0: Introduction</a></li>
  <li><a href="https://xai-hcee.github.io/chapter_1.html">Chapter 1: Psychological foundations of explanations</a></li>
  <li><a href="https://xai-hcee.github.io/chapter_2.html">Chapter 2: Overview of XAI techniques</a></li>
  <li><a href="https://xai-hcee.github.io/chapter_3.html">Chapter 3: Application-grounded human-subject evaluations</a></li>
  <li><a href="https://xai-hcee.github.io/chapter_4.html">Chapter 4: Proxy evaluations through human-provided explanations</a></li>
  <li><a href="https://xai-hcee.github.io/chapter_5.html">Chapter 5: Summary and future directions</a></li>
</ul-->

<h2 id="speakers">Speakers</h2>

<div class="col-md-4">
    <div class="profile height150">
        <div><a href="http://ziningzhu.github.io"><img class="avatar-img" width="150" src="images/zining.png" /></a></div>
        <div style="margin-bottom:40px"><center><b>Zining Zhu</b><br />SIT</center></div>
    </div>
</div>
<div class="col-md-4">
    <div class="profile height150">
        <div><a href="https://hanjiechen.github.io/"><img class="avatar-img" width="150" src="images/hanjie.jpeg" /> </a></div>
        <div style="margin-bottom:40px"><center><b>Hanjie Chen</b><br />Rice</center></div>
    </div>
</div>
<div class="col-md-4">
    <div class="profile height150">
        <div><a href="https://xiye17.github.io"><img class="avatar-img" width="150" src="images/xiye.jpg" /></a></div>
        <div style="margin-bottom:40px"><center><b>Xi Ye</b><br />UAlberta</center></div>
    </div>
</div>
<div class="col-md-4">
    <div class="profile height150">
        <div><a href="https://chenhaot.com"><img class="avatar-img" width="150" src="images/chenhao.jpeg" /></a></div>
        <div style="margin-bottom:40px"><center><b>Chenhao Tan</b><br />UChicago</center></div>
    </div>
</div>
<div class="col-md-4">
    <div class="profile height150">
        <div><a href="https://www.anamarasovic.com/"><img class="avatar-img" width="150" src="images/ana.png" /></a></div>
        <div style="margin-bottom:40px"><center><b>Ana MarasoviÄ‡</b><br />Utah</center></div>
    </div>
</div>
<div class="col-md-4">
    <div class="profile height150">
        <div><a href="https://sarahwie.github.io/"><img class="avatar-img" width="150" src="images/sarahwie.jpeg" /></a></div>
        <div style="margin-bottom:40px"><center><b>Sarah Wiegreffe</b><br />AI2</center></div>
    </div>
</div>
<div class="col-md-4">
    <div class="profile height150">
        <div><a href="https://veronica320.github.io"><img class="avatar-img" width="150" src="images/veronica.jpg" /></a></div>
        <div style="margin-bottom:40px"><center><b>Veronica Qing Lyu</b><br />UPenn</center></div>
    </div>
</div>

<div class="col-md-12">
    <h2>Recommended Reading</h2>
    <ul>
        <li><a href="https://projects.illc.uva.nl/indeep/tutorial/">EACL 24 Tutorial: Transformer-specific Interpretability</a></li>
        <li><a href="https://ziningzhu.notion.site/Explanations-reading-list-56cd203b1d1c4fd79e8fcf319b1560a8">Explanations reading list</a></li>
        <li><a href="https://xai-hcee.github.io">NAACL 22 Tutorial on Human-centered Evaluations of Explanations</a></li>
        <li><a href="https://aclanthology.org/2020.emnlp-tutorials.3/">EMNLP 20 Tutorial: Interpreting Predictions of NLP Models</a></li>
        <li><a href="https://aclanthology.org/2020.acl-tutorials.1/">ACL 20 Tutorial: Interpretability and Analysis in Neural NLP</a></li>
    </ul>
</div>
  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">

    <h2 class="footer-heading">NAACL 24 Tutorial: Explanations in the Era of Language Models</h2>

    <div class="footer-col-3 column">
      <ul>
        <li>The stylesheets come from <a href="https://xai-hcee.github.io/">xai-hcee</a>.</li>
        <li> For questions related to the website please email <a href="explanation-tutorial-2024@googlegroups.com">explanation-tutorial-2024@googlegroups.com</a>.</li>
      </ul>
    </div>



  </div>

</footer>


    </body>
</html>